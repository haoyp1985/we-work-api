# ğŸš€ éƒ¨ç½²æ¶æ„è¯¦ç»†è®¾è®¡
*WeWork Management Platform - Deployment Architecture Design*

## ğŸ“‹ éƒ¨ç½²æ¶æ„æ¦‚è§ˆ

### ğŸ¯ éƒ¨ç½²ç›®æ ‡
- **äº‘åŸç”Ÿæ¶æ„**: åŸºäºå®¹å™¨å’ŒKubernetesçš„ç°ä»£åŒ–éƒ¨ç½²
- **å¤šç¯å¢ƒæ”¯æŒ**: å¼€å‘ã€æµ‹è¯•ã€é¢„ç”Ÿäº§ã€ç”Ÿäº§ç¯å¢ƒéš”ç¦»
- **é«˜å¯ç”¨éƒ¨ç½²**: 99.9%+ å¯ç”¨æ€§ä¿éšœ
- **è‡ªåŠ¨åŒ–è¿ç»´**: ä¸€é”®éƒ¨ç½²ã€è‡ªåŠ¨æ‰©ç¼©å®¹ã€æ•…éšœè‡ªæ„ˆ
- **å®‰å…¨åˆè§„**: ä¼ä¸šçº§å®‰å…¨å’Œåˆè§„è¦æ±‚

### ğŸ—ï¸ éƒ¨ç½²æ¶æ„è®¾è®¡

```mermaid
graph TB
    subgraph "å¤–éƒ¨æµé‡"
        ELB[å¤–éƒ¨è´Ÿè½½å‡è¡¡å™¨]
        CDN[CDNåŠ é€Ÿ]
        DNS[æ™ºèƒ½DNS]
    end
    
    subgraph "Kubernetesé›†ç¾¤"
        subgraph "Ingresså±‚"
            IG1[Nginx Ingress]
            IG2[Istio Gateway]
        end
        
        subgraph "åº”ç”¨å±‚"
            API1[APIæœåŠ¡Pod]
            API2[APIæœåŠ¡Pod]
            API3[APIæœåŠ¡Pod]
            WEB1[WebæœåŠ¡Pod]
            WEB2[WebæœåŠ¡Pod]
        end
        
        subgraph "ä¸­é—´ä»¶å±‚"
            REDIS1[Redisé›†ç¾¤]
            MQ1[RabbitMQé›†ç¾¤]
            ES1[Elasticsearché›†ç¾¤]
        end
        
        subgraph "æ•°æ®å±‚"
            DB1[MySQLä¸»åº“]
            DB2[MySQLä»åº“]
            MINIO1[MinIOå¯¹è±¡å­˜å‚¨]
        end
        
        subgraph "ç›‘æ§å±‚"
            PROM[Prometheus]
            GRAF[Grafana]
            ALERT[AlertManager]
            JAEGER[Jaegerè¿½è¸ª]
        end
    end
    
    subgraph "åŸºç¡€è®¾æ–½"
        HARBOR[Harboré•œåƒä»“åº“]
        NEXUS[Nexusåˆ¶å“åº“]
        VAULT[HashiCorp Vault]
    end
    
    DNS --> ELB
    CDN --> ELB
    ELB --> IG1
    IG1 --> API1
    IG1 --> WEB1
    API1 --> REDIS1
    API1 --> DB1
    PROM --> API1
```

## ğŸ³ å®¹å™¨åŒ–æ¶æ„è®¾è®¡

### Dockeré•œåƒæ„å»ºç­–ç•¥
```dockerfile
# å¤šé˜¶æ®µæ„å»ºä¼˜åŒ–é•œåƒå¤§å°
FROM eclipse-temurin:17-jdk-alpine AS builder

WORKDIR /app

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY pom.xml .
COPY .mvn .mvn
COPY mvnw .

# ä¸‹è½½ä¾èµ–ï¼ˆåˆ©ç”¨Dockerç¼“å­˜ï¼‰
RUN ./mvnw dependency:go-offline -B

# å¤åˆ¶æºç å¹¶æ„å»º
COPY src src
RUN ./mvnw clean package -DskipTests -B

# è¿è¡Œæ—¶é•œåƒ
FROM eclipse-temurin:17-jre-alpine

# å®‰å…¨é…ç½®
RUN addgroup -g 1001 appgroup && \
    adduser -u 1001 -G appgroup -s /bin/sh -D appuser

# å®‰è£…å¿…è¦å·¥å…·
RUN apk add --no-cache curl

WORKDIR /app

# å¤åˆ¶åº”ç”¨æ–‡ä»¶
COPY --from=builder /app/target/*.jar app.jar

# åˆ›å»ºæ—¥å¿—ç›®å½•
RUN mkdir -p /app/logs && \
    chown -R appuser:appgroup /app

# åˆ‡æ¢åˆ°érootç”¨æˆ·
USER appuser

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8080/actuator/health || exit 1

# JVMä¼˜åŒ–å‚æ•°
ENV JAVA_OPTS="-server \
    -XX:+UseG1GC \
    -XX:MaxGCPauseMillis=100 \
    -XX:+UseContainerSupport \
    -XX:MaxRAMPercentage=75.0 \
    -Djava.security.egd=file:/dev/./urandom \
    -Dspring.profiles.active=prod"

EXPOSE 8080

ENTRYPOINT ["sh", "-c", "java $JAVA_OPTS -jar app.jar"]
```

### é•œåƒåˆ†å±‚ä¼˜åŒ–
```dockerfile
# .dockerignore æ–‡ä»¶
.git
.gitignore
README.md
Dockerfile*
docker-compose*
.dockerignore
node_modules
npm-debug.log
.nyc_output
.vscode
.idea
*.swp
*.swo
*~

# åŸºç¡€é•œåƒä¼˜åŒ–
FROM eclipse-temurin:17-jre-alpine AS base

# å®‰è£…åŸºç¡€ä¾èµ–
RUN apk add --no-cache \
    curl \
    bash \
    tzdata \
    fontconfig \
    ttf-dejavu

# è®¾ç½®æ—¶åŒº
RUN cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime && \
    echo "Asia/Shanghai" > /etc/timezone

# åº”ç”¨é•œåƒ
FROM base AS app

WORKDIR /app

# åˆ›å»ºåº”ç”¨ç”¨æˆ·
RUN addgroup -g 1001 spring && \
    adduser -u 1001 -G spring -s /bin/sh -D spring

# å¤åˆ¶åº”ç”¨
ARG JAR_FILE=target/*.jar
COPY ${JAR_FILE} app.jar

# è®¾ç½®æƒé™
RUN chown spring:spring app.jar

USER spring:spring

# å¯åŠ¨è„šæœ¬
COPY --chown=spring:spring docker-entrypoint.sh /usr/local/bin/
RUN chmod +x /usr/local/bin/docker-entrypoint.sh

ENTRYPOINT ["docker-entrypoint.sh"]
```

### åº”ç”¨å¯åŠ¨è„šæœ¬
```bash
#!/bin/bash
# docker-entrypoint.sh

set -e

# é»˜è®¤JVMå‚æ•°
DEFAULT_JVM_OPTS="-server -XX:+UseG1GC -XX:MaxGCPauseMillis=100"

# å®¹å™¨å†…å­˜é™åˆ¶æ„ŸçŸ¥
if [ -n "$MEMORY_LIMIT" ]; then
    # æ ¹æ®å®¹å™¨å†…å­˜é™åˆ¶è®¾ç½®å †å†…å­˜
    HEAP_SIZE=$(echo "$MEMORY_LIMIT * 0.75" | bc)
    JVM_OPTS="$JVM_OPTS -Xmx${HEAP_SIZE}m"
fi

# ç¯å¢ƒç‰¹å®šé…ç½®
case "$SPRING_PROFILES_ACTIVE" in
    "dev")
        JVM_OPTS="$JVM_OPTS -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=*:5005"
        ;;
    "prod")
        JVM_OPTS="$JVM_OPTS -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/app/logs/"
        ;;
esac

# åˆå¹¶æ‰€æœ‰JVMå‚æ•°
FINAL_JVM_OPTS="$DEFAULT_JVM_OPTS $JVM_OPTS $JAVA_OPTS"

echo "Starting application with JVM options: $FINAL_JVM_OPTS"
echo "Active profiles: $SPRING_PROFILES_ACTIVE"

# å¯åŠ¨åº”ç”¨
exec java $FINAL_JVM_OPTS -jar app.jar "$@"
```

## â˜¸ï¸ Kuberneteséƒ¨ç½²é…ç½®

### å‘½åç©ºé—´å’Œèµ„æºé…é¢
```yaml
# namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: wework-platform
  labels:
    name: wework-platform
    environment: production

---
# èµ„æºé…é¢
apiVersion: v1
kind: ResourceQuota
metadata:
  name: wework-platform-quota
  namespace: wework-platform
spec:
  hard:
    requests.cpu: "20"
    requests.memory: 40Gi
    limits.cpu: "40"
    limits.memory: 80Gi
    persistentvolumeclaims: "20"
    pods: "50"
    services: "20"
    secrets: "30"
    configmaps: "30"

---
# é™åˆ¶èŒƒå›´
apiVersion: v1
kind: LimitRange
metadata:
  name: wework-platform-limits
  namespace: wework-platform
spec:
  limits:
  - type: Container
    default:
      cpu: 500m
      memory: 1Gi
    defaultRequest:
      cpu: 100m
      memory: 256Mi
    max:
      cpu: 4
      memory: 8Gi
    min:
      cpu: 50m
      memory: 128Mi
  - type: PersistentVolumeClaim
    max:
      storage: 100Gi
    min:
      storage: 1Gi
```

### åº”ç”¨éƒ¨ç½²é…ç½®
```yaml
# wework-api-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wework-api
  namespace: wework-platform
  labels:
    app: wework-api
    version: v1
    component: backend
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app: wework-api
  template:
    metadata:
      labels:
        app: wework-api
        version: v1
        component: backend
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8080"
        prometheus.io/path: "/actuator/prometheus"
    spec:
      # åäº²å’Œæ€§é…ç½®
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - wework-api
              topologyKey: kubernetes.io/hostname
      
      # æœåŠ¡è´¦æˆ·
      serviceAccountName: wework-api-sa
      
      # å®‰å…¨ä¸Šä¸‹æ–‡
      securityContext:
        runAsNonRoot: true
        runAsUser: 1001
        runAsGroup: 1001
        fsGroup: 1001
      
      # åˆå§‹åŒ–å®¹å™¨
      initContainers:
      - name: wait-for-db
        image: busybox:1.35
        command: ['sh', '-c']
        args:
        - |
          until nc -z mysql-service 3306; do
            echo "Waiting for MySQL..."
            sleep 2
          done
          echo "MySQL is ready!"
      
      containers:
      - name: wework-api
        image: harbor.company.com/wework/wework-api:v1.0.0
        imagePullPolicy: IfNotPresent
        
        ports:
        - name: http
          containerPort: 8080
          protocol: TCP
        - name: management
          containerPort: 8081
          protocol: TCP
        
        # ç¯å¢ƒå˜é‡
        env:
        - name: SPRING_PROFILES_ACTIVE
          value: "prod"
        - name: JAVA_OPTS
          value: "-XX:+UseContainerSupport -XX:MaxRAMPercentage=75.0"
        - name: TZ
          value: "Asia/Shanghai"
        
        # ç¯å¢ƒå˜é‡ä»ConfigMapå’ŒSecretè·å–
        envFrom:
        - configMapRef:
            name: wework-api-config
        - secretRef:
            name: wework-api-secrets
        
        # èµ„æºé™åˆ¶
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1"
        
        # å¥åº·æ£€æŸ¥
        livenessProbe:
          httpGet:
            path: /actuator/health/liveness
            port: management
          initialDelaySeconds: 60
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
        
        readinessProbe:
          httpGet:
            path: /actuator/health/readiness
            port: management
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 3
        
        startupProbe:
          httpGet:
            path: /actuator/health
            port: management
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          failureThreshold: 12
        
        # å·æŒ‚è½½
        volumeMounts:
        - name: logs
          mountPath: /app/logs
        - name: config
          mountPath: /app/config
          readOnly: true
        - name: secrets
          mountPath: /app/secrets
          readOnly: true
        
        # å®‰å…¨ä¸Šä¸‹æ–‡
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
          capabilities:
            drop:
            - ALL
      
      # å·å®šä¹‰
      volumes:
      - name: logs
        emptyDir: {}
      - name: config
        configMap:
          name: wework-api-config
      - name: secrets
        secret:
          secretName: wework-api-secrets
          defaultMode: 0400
      
      # é•œåƒæ‹‰å–å¯†é’¥
      imagePullSecrets:
      - name: harbor-secret
      
      # DNSé…ç½®
      dnsPolicy: ClusterFirst
      
      # é‡å¯ç­–ç•¥
      restartPolicy: Always
      
      # ç»ˆæ­¢å®½é™æœŸ
      terminationGracePeriodSeconds: 30

---
# æœåŠ¡é…ç½®
apiVersion: v1
kind: Service
metadata:
  name: wework-api-service
  namespace: wework-platform
  labels:
    app: wework-api
    component: backend
spec:
  type: ClusterIP
  ports:
  - name: http
    port: 80
    targetPort: 8080
    protocol: TCP
  - name: management
    port: 8081
    targetPort: 8081
    protocol: TCP
  selector:
    app: wework-api

---
# æœåŠ¡è´¦æˆ·
apiVersion: v1
kind: ServiceAccount
metadata:
  name: wework-api-sa
  namespace: wework-platform
  labels:
    app: wework-api

---
# ConfigMapé…ç½®
apiVersion: v1
kind: ConfigMap
metadata:
  name: wework-api-config
  namespace: wework-platform
data:
  application.yml: |
    server:
      port: 8080
      shutdown: graceful
    
    management:
      server:
        port: 8081
      endpoints:
        web:
          exposure:
            include: health,info,metrics,prometheus
      endpoint:
        health:
          show-details: always
          probes:
            enabled: true
    
    spring:
      application:
        name: wework-api
      
      datasource:
        url: jdbc:mysql://mysql-service:3306/wework?useSSL=false&serverTimezone=Asia/Shanghai
        username: ${DB_USERNAME}
        password: ${DB_PASSWORD}
        hikari:
          maximum-pool-size: 20
          minimum-idle: 5
          connection-timeout: 30000
          idle-timeout: 600000
          max-lifetime: 1800000
      
      redis:
        host: redis-service
        port: 6379
        password: ${REDIS_PASSWORD}
        timeout: 3000ms
        jedis:
          pool:
            max-active: 50
            max-idle: 20
            min-idle: 5
            max-wait: 3000ms
    
    logging:
      level:
        com.wework: INFO
        org.springframework.web: DEBUG
      pattern:
        console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
        file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
      file:
        name: /app/logs/application.log
        max-size: 100MB
        max-history: 30

---
# Secreté…ç½®
apiVersion: v1
kind: Secret
metadata:
  name: wework-api-secrets
  namespace: wework-platform
type: Opaque
data:
  DB_USERNAME: d2V3b3Jr  # base64 encoded
  DB_PASSWORD: cGFzc3dvcmQ=  # base64 encoded
  REDIS_PASSWORD: cmVkaXNwYXNz  # base64 encoded
  JWT_SECRET: and0LXNlY3JldC1rZXk=  # base64 encoded
```

### Ingressç½‘å…³é…ç½®
```yaml
# ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: wework-platform-ingress
  namespace: wework-platform
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
    nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
    nginx.ingress.kubernetes.io/proxy-body-size: "50m"
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "60"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "60"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "60"
    nginx.ingress.kubernetes.io/rate-limit: "100"
    nginx.ingress.kubernetes.io/rate-limit-window: "1m"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
spec:
  ingressClassName: nginx
  tls:
  - hosts:
    - api.wework.company.com
    secretName: wework-api-tls
  rules:
  - host: api.wework.company.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: wework-api-service
            port:
              number: 80

---
# Istio Gatewayé…ç½®
apiVersion: networking.istio.io/v1beta1
kind: Gateway
metadata:
  name: wework-platform-gateway
  namespace: wework-platform
spec:
  selector:
    istio: ingressgateway
  servers:
  - port:
      number: 443
      name: https
      protocol: HTTPS
    tls:
      mode: SIMPLE
      credentialName: wework-api-tls
    hosts:
    - api.wework.company.com
  - port:
      number: 80
      name: http
      protocol: HTTP
    hosts:
    - api.wework.company.com
    tls:
      httpsRedirect: true

---
# Istio VirtualServiceé…ç½®
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: wework-platform-vs
  namespace: wework-platform
spec:
  hosts:
  - api.wework.company.com
  gateways:
  - wework-platform-gateway
  http:
  - match:
    - uri:
        prefix: /api/v1/health
    route:
    - destination:
        host: wework-api-service
        port:
          number: 8081
  - match:
    - uri:
        prefix: /api/
    route:
    - destination:
        host: wework-api-service
        port:
          number: 80
    timeout: 30s
    retries:
      attempts: 3
      perTryTimeout: 10s
      retryOn: 5xx,reset,connect-failure,refused-stream
  - match:
    - uri:
        prefix: /
    redirect:
      uri: /api/v1/docs
```

## ğŸŒˆ å¤šç¯å¢ƒéƒ¨ç½²ç­–ç•¥

### ç¯å¢ƒé…ç½®ç®¡ç†
```yaml
# environments/dev/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

namespace: wework-dev

resources:
- ../../base

patches:
- patch: |-
    - op: replace
      path: /spec/replicas
      value: 1
  target:
    kind: Deployment
    name: wework-api

- patch: |-
    - op: replace
      path: /spec/hard/requests.cpu
      value: "4"
    - op: replace
      path: /spec/hard/requests.memory
      value: "8Gi"
  target:
    kind: ResourceQuota
    name: wework-platform-quota

configMapGenerator:
- name: wework-api-config
  files:
  - application-dev.yml

secretGenerator:
- name: wework-api-secrets
  literals:
  - DB_USERNAME=devuser
  - DB_PASSWORD=devpass
  - REDIS_PASSWORD=devredis

images:
- name: harbor.company.com/wework/wework-api
  newTag: dev-latest

---
# environments/staging/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

namespace: wework-staging

resources:
- ../../base

patches:
- patch: |-
    - op: replace
      path: /spec/replicas
      value: 2
  target:
    kind: Deployment
    name: wework-api

configMapGenerator:
- name: wework-api-config
  files:
  - application-staging.yml

secretGenerator:
- name: wework-api-secrets
  literals:
  - DB_USERNAME=staginguser
  - DB_PASSWORD=stagingpass
  - REDIS_PASSWORD=stagingredis

images:
- name: harbor.company.com/wework/wework-api
  newTag: staging-v1.0.0

---
# environments/prod/kustomization.yaml
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization

namespace: wework-platform

resources:
- ../../base
- hpa.yaml
- pdb.yaml

patches:
- patch: |-
    - op: replace
      path: /spec/replicas
      value: 5
  target:
    kind: Deployment
    name: wework-api

- patch: |-
    - op: replace
      path: /spec/template/spec/containers/0/resources/requests/memory
      value: "2Gi"
    - op: replace
      path: /spec/template/spec/containers/0/resources/limits/memory
      value: "4Gi"
  target:
    kind: Deployment
    name: wework-api

configMapGenerator:
- name: wework-api-config
  files:
  - application-prod.yml

secretGenerator:
- name: wework-api-secrets
  envs:
  - secrets.env

images:
- name: harbor.company.com/wework/wework-api
  newTag: v1.0.0
```

### HPAå’ŒPDBé…ç½®
```yaml
# environments/prod/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: wework-api-hpa
  namespace: wework-platform
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: wework-api
  minReplicas: 5
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  - type: Pods
    pods:
      metric:
        name: http_requests_per_second
      target:
        type: AverageValue
        averageValue: "100"
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 50
        periodSeconds: 30

---
# environments/prod/pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: wework-api-pdb
  namespace: wework-platform
spec:
  minAvailable: 3
  selector:
    matchLabels:
      app: wework-api
```

## ğŸ”„ è“ç»¿éƒ¨ç½²å’Œç°åº¦å‘å¸ƒ

### Argo Rolloutsé…ç½®
```yaml
# rollout.yaml
apiVersion: argoproj.io/v1alpha1
kind: Rollout
metadata:
  name: wework-api-rollout
  namespace: wework-platform
spec:
  replicas: 5
  strategy:
    canary:
      canaryService: wework-api-canary
      stableService: wework-api-stable
      trafficRouting:
        istio:
          virtualService:
            name: wework-platform-vs
            routes:
            - primary
          destinationRule:
            name: wework-api-dr
            canarySubsetName: canary
            stableSubsetName: stable
      steps:
      - setWeight: 10
      - pause: {duration: 2m}
      - setWeight: 20
      - pause: {duration: 2m}
      - setWeight: 40
      - pause: {duration: 2m}
      - setWeight: 60
      - pause: {duration: 2m}
      - setWeight: 80
      - pause: {duration: 2m}
      - setWeight: 100
      maxSurge: "25%"
      maxUnavailable: 0
      analysis:
        templates:
        - templateName: success-rate
        startingStep: 1
        args:
        - name: service-name
          value: wework-api-canary
  selector:
    matchLabels:
      app: wework-api
  template:
    metadata:
      labels:
        app: wework-api
    spec:
      containers:
      - name: wework-api
        image: harbor.company.com/wework/wework-api:v1.0.0
        ports:
        - name: http
          containerPort: 8080
          protocol: TCP
        resources:
          requests:
            memory: "2Gi"
            cpu: "500m"
          limits:
            memory: "4Gi"
            cpu: "1"

---
# åˆ†ææ¨¡æ¿
apiVersion: argoproj.io/v1alpha1
kind: AnalysisTemplate
metadata:
  name: success-rate
  namespace: wework-platform
spec:
  args:
  - name: service-name
  metrics:
  - name: success-rate
    successCondition: result[0] >= 0.95
    provider:
      prometheus:
        address: http://prometheus:9090
        query: |
          sum(rate(http_requests_total{service="{{args.service-name}}",code!~"5.."}[2m])) /
          sum(rate(http_requests_total{service="{{args.service-name}}"}[2m]))
  - name: avg-response-time
    successCondition: result[0] <= 0.5
    provider:
      prometheus:
        address: http://prometheus:9090
        query: |
          histogram_quantile(0.95,
            sum(rate(http_request_duration_seconds_bucket{service="{{args.service-name}}"}[2m])) by (le)
          )

---
# Canary Service
apiVersion: v1
kind: Service
metadata:
  name: wework-api-canary
  namespace: wework-platform
spec:
  ports:
  - port: 80
    targetPort: 8080
    protocol: TCP
  selector:
    app: wework-api

---
# Stable Service  
apiVersion: v1
kind: Service
metadata:
  name: wework-api-stable
  namespace: wework-platform
spec:
  ports:
  - port: 80
    targetPort: 8080
    protocol: TCP
  selector:
    app: wework-api

---
# Destination Rule
apiVersion: networking.istio.io/v1beta1
kind: DestinationRule
metadata:
  name: wework-api-dr
  namespace: wework-platform
spec:
  host: wework-api-service
  subsets:
  - name: stable
    labels:
      app: wework-api
  - name: canary
    labels:
      app: wework-api
```

### è“ç»¿éƒ¨ç½²è„šæœ¬
```bash
#!/bin/bash
# blue-green-deploy.sh

set -e

NAMESPACE="wework-platform"
APP_NAME="wework-api"
NEW_VERSION=$1
CURRENT_COLOR=$(kubectl get service ${APP_NAME}-active -n ${NAMESPACE} -o jsonpath='{.spec.selector.color}' 2>/dev/null || echo "blue")

if [ "$CURRENT_COLOR" = "blue" ]; then
    NEW_COLOR="green"
    OLD_COLOR="blue"
else
    NEW_COLOR="blue"
    OLD_COLOR="green"
fi

echo "Current color: $CURRENT_COLOR"
echo "Deploying to: $NEW_COLOR"
echo "New version: $NEW_VERSION"

# 1. éƒ¨ç½²æ–°ç‰ˆæœ¬åˆ°éæ´»è·ƒç¯å¢ƒ
echo "Deploying new version to $NEW_COLOR environment..."
kubectl set image deployment/${APP_NAME}-${NEW_COLOR} \
    ${APP_NAME}=harbor.company.com/wework/${APP_NAME}:${NEW_VERSION} \
    -n ${NAMESPACE}

# 2. ç­‰å¾…éƒ¨ç½²å®Œæˆ
echo "Waiting for $NEW_COLOR deployment to be ready..."
kubectl rollout status deployment/${APP_NAME}-${NEW_COLOR} -n ${NAMESPACE} --timeout=300s

# 3. å¥åº·æ£€æŸ¥
echo "Performing health check on $NEW_COLOR environment..."
for i in {1..30}; do
    if kubectl exec -n ${NAMESPACE} deployment/${APP_NAME}-${NEW_COLOR} -- \
        curl -f http://localhost:8080/actuator/health > /dev/null 2>&1; then
        echo "Health check passed!"
        break
    fi
    echo "Health check attempt $i failed, retrying..."
    sleep 10
done

# 4. çƒŸé›¾æµ‹è¯•
echo "Running smoke tests on $NEW_COLOR environment..."
SMOKE_TEST_POD=$(kubectl run smoke-test-${NEW_COLOR} \
    --image=curlimages/curl:latest \
    --rm -i --restart=Never \
    -n ${NAMESPACE} \
    -- curl -f http://${APP_NAME}-${NEW_COLOR}:80/api/v1/health)

if [ $? -eq 0 ]; then
    echo "Smoke tests passed!"
else
    echo "Smoke tests failed! Rolling back..."
    exit 1
fi

# 5. åˆ‡æ¢æµé‡
echo "Switching traffic to $NEW_COLOR environment..."
kubectl patch service ${APP_NAME}-active \
    -p '{"spec":{"selector":{"color":"'${NEW_COLOR}'"}}}' \
    -n ${NAMESPACE}

# 6. éªŒè¯åˆ‡æ¢
echo "Verifying traffic switch..."
sleep 10
kubectl get service ${APP_NAME}-active -n ${NAMESPACE} -o yaml

# 7. æ¸…ç†æ—§ç‰ˆæœ¬ï¼ˆå¯é€‰ï¼‰
read -p "Do you want to scale down the $OLD_COLOR environment? (y/n): " -n 1 -r
echo
if [[ $REPLY =~ ^[Yy]$ ]]; then
    echo "Scaling down $OLD_COLOR environment..."
    kubectl scale deployment ${APP_NAME}-${OLD_COLOR} --replicas=0 -n ${NAMESPACE}
fi

echo "Blue-green deployment completed successfully!"
echo "Active environment: $NEW_COLOR"
echo "Version deployed: $NEW_VERSION"
```

## ğŸ”’ ç½‘ç»œå®‰å…¨å’Œç­–ç•¥

### ç½‘ç»œç­–ç•¥é…ç½®
```yaml
# network-policy.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: wework-platform-netpol
  namespace: wework-platform
spec:
  podSelector:
    matchLabels:
      app: wework-api
  policyTypes:
  - Ingress
  - Egress
  
  # å…¥ç«™è§„åˆ™
  ingress:
  # å…è®¸æ¥è‡ªIngress Controllerçš„æµé‡
  - from:
    - namespaceSelector:
        matchLabels:
          name: ingress-nginx
    ports:
    - protocol: TCP
      port: 8080
  
  # å…è®¸æ¥è‡ªåŒä¸€å‘½åç©ºé—´çš„æµé‡
  - from:
    - namespaceSelector:
        matchLabels:
          name: wework-platform
    ports:
    - protocol: TCP
      port: 8080
    - protocol: TCP
      port: 8081
  
  # å…è®¸æ¥è‡ªç›‘æ§ç³»ç»Ÿçš„æµé‡
  - from:
    - namespaceSelector:
        matchLabels:
          name: monitoring
    ports:
    - protocol: TCP
      port: 8081
  
  # å‡ºç«™è§„åˆ™
  egress:
  # å…è®¸è®¿é—®æ•°æ®åº“
  - to:
    - podSelector:
        matchLabels:
          app: mysql
    ports:
    - protocol: TCP
      port: 3306
  
  # å…è®¸è®¿é—®Redis
  - to:
    - podSelector:
        matchLabels:
          app: redis
    ports:
    - protocol: TCP
      port: 6379
  
  # å…è®¸DNSæŸ¥è¯¢
  - to: []
    ports:
    - protocol: UDP
      port: 53
    - protocol: TCP
      port: 53
  
  # å…è®¸HTTPSå‡ºç«™ï¼ˆç”¨äºå¤–éƒ¨APIè°ƒç”¨ï¼‰
  - to: []
    ports:
    - protocol: TCP
      port: 443

---
# Istio AuthorizationPolicy
apiVersion: security.istio.io/v1beta1
kind: AuthorizationPolicy
metadata:
  name: wework-api-authz
  namespace: wework-platform
spec:
  selector:
    matchLabels:
      app: wework-api
  rules:
  # å…è®¸å¥åº·æ£€æŸ¥
  - to:
    - operation:
        paths: ["/actuator/health", "/actuator/health/*"]
  
  # éœ€è¦JWTè®¤è¯çš„API
  - from:
    - source:
        requestPrincipals: ["*"]
    to:
    - operation:
        paths: ["/api/v1/*"]
    when:
    - key: request.headers[authorization]
      values: ["Bearer *"]
  
  # å…è®¸å…¬å¼€çš„APIæ–‡æ¡£
  - to:
    - operation:
        paths: ["/api/v1/docs", "/api/v1/docs/*"]

---
# PeerAuthentication
apiVersion: security.istio.io/v1beta1
kind: PeerAuthentication
metadata:
  name: wework-platform-pa
  namespace: wework-platform
spec:
  mtls:
    mode: STRICT
```

### Podå®‰å…¨ç­–ç•¥
```yaml
# pod-security-policy.yaml
apiVersion: policy/v1beta1
kind: PodSecurityPolicy
metadata:
  name: wework-platform-psp
spec:
  privileged: false
  allowPrivilegeEscalation: false
  requiredDropCapabilities:
    - ALL
  volumes:
    - 'configMap'
    - 'emptyDir'
    - 'projected'
    - 'secret'
    - 'downwardAPI'
    - 'persistentVolumeClaim'
  runAsUser:
    rule: 'MustRunAsNonRoot'
  seLinux:
    rule: 'RunAsAny'
  fsGroup:
    rule: 'RunAsAny'
  readOnlyRootFilesystem: true

---
# ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: wework-platform-psp-user
rules:
- apiGroups: ['policy']
  resources: ['podsecuritypolicies']
  verbs: ['use']
  resourceNames:
  - wework-platform-psp

---
# ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: wework-platform-psp-user
roleRef:
  kind: ClusterRole
  name: wework-platform-psp-user
  apiGroup: rbac.authorization.k8s.io
subjects:
- kind: ServiceAccount
  name: wework-api-sa
  namespace: wework-platform
```

## ğŸ’¾ å­˜å‚¨å’Œæ•°æ®ç®¡ç†

### æŒä¹…åŒ–å­˜å‚¨é…ç½®
```yaml
# storage.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: fast-ssd
  annotations:
    storageclass.kubernetes.io/is-default-class: "false"
provisioner: kubernetes.io/aws-ebs
parameters:
  type: gp3
  iops: "3000"
  throughput: "125"
  encrypted: "true"
allowVolumeExpansion: true
volumeBindingMode: WaitForFirstConsumer

---
# MySQLæŒä¹…åŒ–å·
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: mysql-pvc
  namespace: wework-platform
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: fast-ssd
  resources:
    requests:
      storage: 100Gi

---
# RedisæŒä¹…åŒ–å·
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: redis-pvc
  namespace: wework-platform
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: fast-ssd
  resources:
    requests:
      storage: 20Gi

---
# æ—¥å¿—æŒä¹…åŒ–å·
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: logs-pvc
  namespace: wework-platform
spec:
  accessModes:
    - ReadWriteMany
  storageClassName: nfs-client
  resources:
    requests:
      storage: 50Gi
```

### å¤‡ä»½ç­–ç•¥é…ç½®
```yaml
# backup-cronjob.yaml
apiVersion: batch/v1
kind: CronJob
metadata:
  name: mysql-backup
  namespace: wework-platform
spec:
  schedule: "0 2 * * *"  # æ¯å¤©å‡Œæ™¨2ç‚¹
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: mysql-backup
            image: mysql:8.0
            command:
            - /bin/bash
            - -c
            - |
              BACKUP_FILE="/backup/mysql-backup-$(date +%Y%m%d-%H%M%S).sql"
              mysqldump -h mysql-service -u root -p$MYSQL_ROOT_PASSWORD \
                --single-transaction --routines --triggers wework > $BACKUP_FILE
              
              # å‹ç¼©å¤‡ä»½æ–‡ä»¶
              gzip $BACKUP_FILE
              
              # åˆ é™¤7å¤©å‰çš„å¤‡ä»½
              find /backup -name "mysql-backup-*.sql.gz" -mtime +7 -delete
              
              echo "Backup completed: $BACKUP_FILE.gz"
            env:
            - name: MYSQL_ROOT_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: mysql-secret
                  key: root-password
            volumeMounts:
            - name: backup-storage
              mountPath: /backup
          volumes:
          - name: backup-storage
            persistentVolumeClaim:
              claimName: backup-pvc
          restartPolicy: OnFailure

---
# Rediså¤‡ä»½é…ç½®
apiVersion: batch/v1
kind: CronJob
metadata:
  name: redis-backup
  namespace: wework-platform
spec:
  schedule: "0 3 * * *"  # æ¯å¤©å‡Œæ™¨3ç‚¹
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: redis-backup
            image: redis:7-alpine
            command:
            - /bin/sh
            - -c
            - |
              BACKUP_FILE="/backup/redis-backup-$(date +%Y%m%d-%H%M%S).rdb"
              redis-cli -h redis-service -a $REDIS_PASSWORD --rdb $BACKUP_FILE
              
              # å‹ç¼©å¤‡ä»½æ–‡ä»¶
              gzip $BACKUP_FILE
              
              # åˆ é™¤7å¤©å‰çš„å¤‡ä»½
              find /backup -name "redis-backup-*.rdb.gz" -mtime +7 -delete
              
              echo "Redis backup completed: $BACKUP_FILE.gz"
            env:
            - name: REDIS_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: redis-secret
                  key: password
            volumeMounts:
            - name: backup-storage
              mountPath: /backup
          volumes:
          - name: backup-storage
            persistentVolumeClaim:
              claimName: backup-pvc
          restartPolicy: OnFailure
```

## ğŸ¯ éƒ¨ç½²æ¶æ„æ€»ç»“

### æ ¸å¿ƒéƒ¨ç½²ç‰¹æ€§
1. **äº‘åŸç”Ÿæ¶æ„**: åŸºäºKubernetesçš„ç°ä»£åŒ–å®¹å™¨éƒ¨ç½²
2. **å¤šç¯å¢ƒç®¡ç†**: å¼€å‘ã€æµ‹è¯•ã€é¢„ç”Ÿäº§ã€ç”Ÿäº§ç¯å¢ƒéš”ç¦»
3. **è‡ªåŠ¨åŒ–éƒ¨ç½²**: è“ç»¿éƒ¨ç½²ã€ç°åº¦å‘å¸ƒã€æ»šåŠ¨æ›´æ–°
4. **é«˜å¯ç”¨ä¿éšœ**: å¤šå‰¯æœ¬ã€åäº²å’Œæ€§ã€æ•…éšœè‡ªæ„ˆ
5. **å®‰å…¨åˆè§„**: ç½‘ç»œç­–ç•¥ã€å®‰å…¨ä¸Šä¸‹æ–‡ã€RBACæƒé™
6. **å­˜å‚¨ç®¡ç†**: æŒä¹…åŒ–å­˜å‚¨ã€è‡ªåŠ¨å¤‡ä»½ã€æ•°æ®æ¢å¤

### éƒ¨ç½²æŒ‡æ ‡
- **éƒ¨ç½²æ•ˆç‡**: ä¸€é”®éƒ¨ç½² < 5åˆ†é’Ÿ
- **å›æ»šé€Ÿåº¦**: æ•…éšœå›æ»š < 2åˆ†é’Ÿ  
- **å¯ç”¨æ€§**: éƒ¨ç½²è¿‡ç¨‹é›¶åœæœº
- **å®‰å…¨ç­‰çº§**: ä¼ä¸šçº§å®‰å…¨åˆè§„
- **æ‰©å±•æ€§**: æ”¯æŒå¤šé›†ç¾¤ã€å¤šåŒºåŸŸéƒ¨ç½²

### æŠ€æœ¯æ ˆ
- **å®¹å™¨æŠ€æœ¯**: Dockerã€containerd
- **ç¼–æ’å¹³å°**: Kubernetesã€Helm
- **æœåŠ¡ç½‘æ ¼**: Istioã€Envoy
- **æŒç»­éƒ¨ç½²**: Argo CDã€Argo Rollouts
- **ç›‘æ§å‘Šè­¦**: Prometheusã€Grafana
- **æ—¥å¿—ç®¡ç†**: ELK Stackã€Fluent Bit
