# âš¡ æ€§èƒ½ä¼˜åŒ–è¯¦ç»†è®¾è®¡
*WeWork Management Platform - Performance Optimization Design*

## ğŸ“‹ æ€§èƒ½ä¼˜åŒ–æ¦‚è§ˆ

### ğŸ¯ æ€§èƒ½ä¼˜åŒ–ç›®æ ‡
- **å“åº”æ—¶é—´**: APIå“åº”æ—¶é—´ < 200ms (P99)
- **ååé‡**: æ”¯æŒ10000+ QPSå¹¶å‘è¯·æ±‚
- **èµ„æºåˆ©ç”¨ç‡**: CPUä½¿ç”¨ç‡ < 70%, å†…å­˜ä½¿ç”¨ç‡ < 80%
- **å¯ç”¨æ€§**: ç³»ç»Ÿå¯ç”¨æ€§ > 99.9%
- **æ‰©å±•æ€§**: æ”¯æŒæ°´å¹³æ‰©å±•åˆ°100+èŠ‚ç‚¹

### ğŸ—ï¸ æ€§èƒ½ä¼˜åŒ–æ¶æ„

```mermaid
graph TB
    subgraph "åº”ç”¨å±‚ä¼˜åŒ–"
        A1[JVMè°ƒä¼˜]
        A2[ä»£ç ä¼˜åŒ–]
        A3[å¼‚æ­¥å¤„ç†]
        A4[è¿æ¥æ± ä¼˜åŒ–]
        A5[çº¿ç¨‹æ± ä¼˜åŒ–]
    end
    
    subgraph "æ•°æ®å±‚ä¼˜åŒ–"
        D1[æŸ¥è¯¢ä¼˜åŒ–]
        D2[ç´¢å¼•ä¼˜åŒ–]
        D3[åˆ†åº“åˆ†è¡¨]
        D4[è¯»å†™åˆ†ç¦»]
        D5[è¿æ¥æ± ç®¡ç†]
    end
    
    subgraph "ç¼“å­˜å±‚ä¼˜åŒ–"
        C1[å¤šçº§ç¼“å­˜]
        C2[ç¼“å­˜é¢„çƒ­]
        C3[ç¼“å­˜é˜²æŠ¤]
        C4[ç¼“å­˜æ·˜æ±°]
        C5[ç¼“å­˜å‹ç¼©]
    end
    
    subgraph "ç½‘ç»œå±‚ä¼˜åŒ–"
        N1[è´Ÿè½½å‡è¡¡]
        N2[CDNåŠ é€Ÿ]
        N3[è¿æ¥å¤ç”¨]
        N4[æ•°æ®å‹ç¼©]
        N5[åè®®ä¼˜åŒ–]
    end
    
    subgraph "ç³»ç»Ÿå±‚ä¼˜åŒ–"
        S1[èµ„æºç®¡ç†]
        S2[å®¹å™¨ä¼˜åŒ–]
        S3[å­˜å‚¨ä¼˜åŒ–]
        S4[ç›‘æ§è°ƒä¼˜]
        S5[è‡ªåŠ¨æ‰©ç¼©å®¹]
    end
```

## ğŸš€ åº”ç”¨å±‚æ€§èƒ½ä¼˜åŒ–

### JVMæ€§èƒ½è°ƒä¼˜
```bash
# ç”Ÿäº§ç¯å¢ƒJVMå‚æ•°é…ç½®
JAVA_OPTS="
# å †å†…å­˜é…ç½®
-Xms4g -Xmx4g
-XX:NewRatio=1
-XX:SurvivorRatio=8

# åƒåœ¾å›æ”¶å™¨é…ç½® (G1GC)
-XX:+UseG1GC
-XX:MaxGCPauseMillis=100
-XX:G1HeapRegionSize=16m
-XX:G1MixedGCCountTarget=8
-XX:InitiatingHeapOccupancyPercent=45

# å…ƒç©ºé—´é…ç½®
-XX:MetaspaceSize=256m
-XX:MaxMetaspaceSize=512m

# ç›´æ¥å†…å­˜é…ç½®
-XX:MaxDirectMemorySize=1g

# GCæ—¥å¿—é…ç½®
-XX:+PrintGC
-XX:+PrintGCDetails
-XX:+PrintGCTimeStamps
-XX:+PrintGCApplicationStoppedTime
-Xloggc:/var/log/gc/gc.log
-XX:+UseGCLogFileRotation
-XX:NumberOfGCLogFiles=5
-XX:GCLogFileSize=100M

# å†…å­˜æº¢å‡ºå¤„ç†
-XX:+HeapDumpOnOutOfMemoryError
-XX:HeapDumpPath=/var/log/heapdump/

# æ€§èƒ½ç›‘æ§
-XX:+PrintGCApplicationConcurrentTime
-XX:+PrintStringDeduplicationStatistics

# JITç¼–è¯‘ä¼˜åŒ–
-XX:CompileThreshold=10000
-XX:+UseCompressedOops
-XX:+UseCompressedClassPointers
"
```

### Spring Bootåº”ç”¨ä¼˜åŒ–é…ç½®
```yaml
# application-prod.yml
server:
  port: 8080
  tomcat:
    threads:
      max: 200
      min-spare: 50
    connection-timeout: 20000
    keep-alive-timeout: 60000
    max-connections: 8192
    accept-count: 100
    max-http-form-post-size: 2MB
    max-swallow-size: 2MB

spring:
  # æ•°æ®æºé…ç½®ä¼˜åŒ–
  datasource:
    hikari:
      minimum-idle: 10
      maximum-pool-size: 50
      connection-timeout: 30000
      idle-timeout: 600000
      max-lifetime: 1800000
      validation-timeout: 5000
      pool-name: HikariCP
      register-mbeans: true
      
  # JPAä¼˜åŒ–é…ç½®
  jpa:
    hibernate:
      ddl-auto: none
    properties:
      hibernate:
        # æ‰¹å¤„ç†ä¼˜åŒ–
        jdbc.batch_size: 50
        order_inserts: true
        order_updates: true
        # æŸ¥è¯¢ä¼˜åŒ–
        default_batch_fetch_size: 16
        max_fetch_depth: 3
        # äºŒçº§ç¼“å­˜
        cache.use_second_level_cache: true
        cache.use_query_cache: true
        cache.region.factory_class: org.hibernate.cache.jcache.JCacheRegionFactory
        
  # Redisé…ç½®ä¼˜åŒ–
  redis:
    jedis:
      pool:
        max-active: 50
        max-idle: 20
        min-idle: 5
        max-wait: 3000ms
    timeout: 3000ms
    
  # å¼‚æ­¥é…ç½®
  task:
    execution:
      pool:
        core-size: 8
        max-size: 50
        queue-capacity: 1000
        keep-alive: 60s
      thread-name-prefix: async-task-
    scheduling:
      pool:
        size: 5
      thread-name-prefix: scheduled-task-
```

### å¼‚æ­¥å¤„ç†ä¼˜åŒ–
```java
@Configuration
@EnableAsync
public class AsyncConfiguration {
    
    // ä¸šåŠ¡å¼‚æ­¥çº¿ç¨‹æ± 
    @Bean("businessExecutor")
    public Executor businessExecutor() {
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        
        // æ ¸å¿ƒçº¿ç¨‹æ•°ï¼šCPUæ ¸å¿ƒæ•°
        executor.setCorePoolSize(Runtime.getRuntime().availableProcessors());
        
        // æœ€å¤§çº¿ç¨‹æ•°ï¼šCPUæ ¸å¿ƒæ•° * 2
        executor.setMaxPoolSize(Runtime.getRuntime().availableProcessors() * 2);
        
        // é˜Ÿåˆ—å®¹é‡
        executor.setQueueCapacity(1000);
        
        // çº¿ç¨‹å­˜æ´»æ—¶é—´
        executor.setKeepAliveSeconds(60);
        
        // çº¿ç¨‹åå‰ç¼€
        executor.setThreadNamePrefix("business-");
        
        // æ‹’ç»ç­–ç•¥ï¼šè°ƒç”¨è€…æ‰§è¡Œ
        executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());
        
        // ç­‰å¾…ä»»åŠ¡å®Œæˆ
        executor.setWaitForTasksToCompleteOnShutdown(true);
        executor.setAwaitTerminationSeconds(60);
        
        executor.initialize();
        return executor;
    }
    
    // IOå¯†é›†å‹çº¿ç¨‹æ± 
    @Bean("ioExecutor")
    public Executor ioExecutor() {
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        
        // IOå¯†é›†å‹ï¼šçº¿ç¨‹æ•°å¯ä»¥è®¾ç½®æ›´é«˜
        executor.setCorePoolSize(20);
        executor.setMaxPoolSize(100);
        executor.setQueueCapacity(2000);
        executor.setKeepAliveSeconds(300);
        executor.setThreadNamePrefix("io-");
        executor.setRejectedExecutionHandler(new ThreadPoolExecutor.CallerRunsPolicy());
        
        executor.initialize();
        return executor;
    }
}

// å¼‚æ­¥æœåŠ¡ç¤ºä¾‹
@Service
public class AsyncMessageService {
    
    @Async("businessExecutor")
    @Retryable(value = {Exception.class}, maxAttempts = 3, backoff = @Backoff(delay = 1000))
    public CompletableFuture<Void> sendMessageAsync(MessageRequest request) {
        try {
            // å¼‚æ­¥å‘é€æ¶ˆæ¯
            messageService.sendMessage(request);
            return CompletableFuture.completedFuture(null);
        } catch (Exception e) {
            log.error("Failed to send message async", e);
            return CompletableFuture.failedFuture(e);
        }
    }
    
    @Async("ioExecutor")
    public CompletableFuture<List<MessageResult>> batchProcessMessages(List<MessageRequest> requests) {
        List<CompletableFuture<MessageResult>> futures = requests.stream()
            .map(request -> CompletableFuture.supplyAsync(() -> {
                return processMessage(request);
            }, ioExecutor))
            .collect(Collectors.toList());
        
        return CompletableFuture.allOf(futures.toArray(new CompletableFuture[0]))
            .thenApply(v -> futures.stream()
                .map(CompletableFuture::join)
                .collect(Collectors.toList()));
    }
}
```

### ä»£ç å±‚é¢ä¼˜åŒ–
```java
// å¯¹è±¡æ± ä¼˜åŒ–
@Component
public class ObjectPoolOptimization {
    
    // StringBuilderå¯¹è±¡æ± 
    private final ObjectPool<StringBuilder> stringBuilderPool = 
        new GenericObjectPool<>(new StringBuilderPoolFactory());
    
    // ä½¿ç”¨å¯¹è±¡æ± é¿å…é¢‘ç¹åˆ›å»ºå¯¹è±¡
    public String buildString(List<String> parts) {
        StringBuilder sb = null;
        try {
            sb = stringBuilderPool.borrowObject();
            sb.setLength(0); // é‡ç½®
            
            for (String part : parts) {
                sb.append(part);
            }
            
            return sb.toString();
        } catch (Exception e) {
            throw new RuntimeException("Failed to build string", e);
        } finally {
            if (sb != null) {
                try {
                    stringBuilderPool.returnObject(sb);
                } catch (Exception e) {
                    log.warn("Failed to return StringBuilder to pool", e);
                }
            }
        }
    }
    
    // æ‰¹é‡å¤„ç†ä¼˜åŒ–
    public void batchProcess(List<MessageRecord> records) {
        int batchSize = 100;
        
        for (int i = 0; i < records.size(); i += batchSize) {
            int endIndex = Math.min(i + batchSize, records.size());
            List<MessageRecord> batch = records.subList(i, endIndex);
            
            // æ‰¹é‡å¤„ç†
            processBatch(batch);
        }
    }
    
    // æµå¼å¤„ç†ä¼˜åŒ–
    public List<ProcessedMessage> processMessagesStream(Stream<MessageRecord> messageStream) {
        return messageStream
            .parallel() // å¹¶è¡Œå¤„ç†
            .filter(this::isValidMessage)
            .map(this::processMessage)
            .collect(Collectors.toList());
    }
}

// åºåˆ—åŒ–ä¼˜åŒ–
@Component
public class SerializationOptimization {
    
    private final ObjectMapper objectMapper;
    
    public SerializationOptimization() {
        this.objectMapper = new ObjectMapper();
        
        // ä¼˜åŒ–é…ç½®
        objectMapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false);
        objectMapper.configure(SerializationFeature.FAIL_ON_EMPTY_BEANS, false);
        objectMapper.setDefaultPropertyInclusion(JsonInclude.Include.NON_NULL);
        
        // æ³¨å†Œæ¨¡å—
        objectMapper.registerModule(new JavaTimeModule());
        
        // ç¦ç”¨æ—¶é—´æˆ³
        objectMapper.disable(SerializationFeature.WRITE_DATES_AS_TIMESTAMPS);
    }
    
    // ä½¿ç”¨å­—èŠ‚ç çº§åºåˆ—åŒ–ï¼ˆKryoï¼‰
    private final Kryo kryo = new Kryo();
    
    public byte[] serializeWithKryo(Object obj) {
        try (ByteArrayOutputStream baos = new ByteArrayOutputStream();
             Output output = new Output(baos)) {
            
            kryo.writeObject(output, obj);
            output.flush();
            return baos.toByteArray();
        } catch (IOException e) {
            throw new RuntimeException("Kryo serialization failed", e);
        }
    }
    
    public <T> T deserializeWithKryo(byte[] data, Class<T> clazz) {
        try (Input input = new Input(data)) {
            return kryo.readObject(input, clazz);
        }
    }
}
```

## ğŸ—„ï¸ æ•°æ®åº“æ€§èƒ½ä¼˜åŒ–

### æŸ¥è¯¢ä¼˜åŒ–ç­–ç•¥
```java
@Repository
public class OptimizedMessageRepository {
    
    @PersistenceContext
    private EntityManager entityManager;
    
    // ä½¿ç”¨åŸç”ŸSQLä¼˜åŒ–å¤æ‚æŸ¥è¯¢
    @Query(value = """
        SELECT m.message_id, m.content, m.status, a.account_name, a.phone
        FROM message_records m
        INNER JOIN wework_accounts a ON m.account_id = a.account_id
        WHERE m.created_at >= :startDate 
        AND m.status IN :statuses
        AND a.status = 'ONLINE'
        ORDER BY m.created_at DESC
        LIMIT :limit OFFSET :offset
        """, nativeQuery = true)
    List<Object[]> findMessagesWithAccountInfo(
        @Param("startDate") LocalDateTime startDate,
        @Param("statuses") List<String> statuses,
        @Param("limit") int limit,
        @Param("offset") int offset
    );
    
    // æ‰¹é‡æ’å…¥ä¼˜åŒ–
    @Transactional
    public void batchInsertMessages(List<MessageRecord> messages) {
        int batchSize = 100;
        
        for (int i = 0; i < messages.size(); i++) {
            entityManager.persist(messages.get(i));
            
            if (i % batchSize == 0 && i > 0) {
                entityManager.flush();
                entityManager.clear();
            }
        }
        
        entityManager.flush();
        entityManager.clear();
    }
    
    // æ¸¸æ ‡åˆ†é¡µæŸ¥è¯¢ï¼ˆå¤§æ•°æ®é‡ï¼‰
    public Page<MessageRecord> findWithCursorPagination(String lastId, int pageSize) {
        CriteriaBuilder cb = entityManager.getCriteriaBuilder();
        CriteriaQuery<MessageRecord> query = cb.createQuery(MessageRecord.class);
        Root<MessageRecord> root = query.from(MessageRecord.class);
        
        List<Predicate> predicates = new ArrayList<>();
        
        if (lastId != null) {
            predicates.add(cb.greaterThan(root.get("messageId"), lastId));
        }
        
        query.where(predicates.toArray(new Predicate[0]));
        query.orderBy(cb.asc(root.get("messageId")));
        
        TypedQuery<MessageRecord> typedQuery = entityManager.createQuery(query);
        typedQuery.setMaxResults(pageSize + 1); // +1 åˆ¤æ–­æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ
        
        List<MessageRecord> results = typedQuery.getResultList();
        boolean hasNext = results.size() > pageSize;
        
        if (hasNext) {
            results = results.subList(0, pageSize);
        }
        
        return new PageImpl<>(results, PageRequest.of(0, pageSize), hasNext ? -1 : results.size());
    }
}
```

### ç´¢å¼•ä¼˜åŒ–è®¾è®¡
```sql
-- æ¶ˆæ¯è®°å½•è¡¨ç´¢å¼•ä¼˜åŒ–
CREATE TABLE message_records (
    message_id VARCHAR(32) PRIMARY KEY,
    account_id VARCHAR(32) NOT NULL,
    content TEXT,
    message_type VARCHAR(20) NOT NULL,
    status VARCHAR(20) NOT NULL DEFAULT 'PENDING',
    created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    sent_at TIMESTAMP NULL,
    target_user VARCHAR(100),
    
    -- å¤åˆç´¢å¼•ï¼šåŸºäºæŸ¥è¯¢æ¨¡å¼è®¾è®¡
    INDEX idx_account_status_created (account_id, status, created_at DESC),
    INDEX idx_status_created (status, created_at DESC),
    INDEX idx_created_status (created_at DESC, status),
    INDEX idx_target_user_created (target_user, created_at DESC),
    
    -- è¦†ç›–ç´¢å¼•ï¼šé¿å…å›è¡¨æŸ¥è¯¢
    INDEX idx_cover_list (account_id, status, created_at DESC, message_type, target_user),
    
    -- å‰ç¼€ç´¢å¼•ï¼šèŠ‚çœç©ºé—´
    INDEX idx_content_prefix (content(100)),
    
    -- å‡½æ•°ç´¢å¼•ï¼šæ”¯æŒç‰¹æ®ŠæŸ¥è¯¢
    INDEX idx_date_part ((DATE(created_at))),
    
    -- å¤–é”®çº¦æŸ
    FOREIGN KEY (account_id) REFERENCES wework_accounts(account_id)
) ENGINE=InnoDB 
  DEFAULT CHARSET=utf8mb4 
  COLLATE=utf8mb4_unicode_ci
  ROW_FORMAT=DYNAMIC
  PARTITION BY RANGE (TO_DAYS(created_at)) (
    PARTITION p202401 VALUES LESS THAN (TO_DAYS('2024-02-01')),
    PARTITION p202402 VALUES LESS THAN (TO_DAYS('2024-03-01')),
    PARTITION p202403 VALUES LESS THAN (TO_DAYS('2024-04-01')),
    -- ... å…¶ä»–åˆ†åŒº
    PARTITION pmax VALUES LESS THAN MAXVALUE
  );

-- ç´¢å¼•ä½¿ç”¨åˆ†æ
EXPLAIN SELECT 
    message_id, content, status, created_at 
FROM message_records 
WHERE account_id = 'acc123' 
  AND status IN ('SENT', 'DELIVERED') 
  AND created_at >= '2024-01-01' 
ORDER BY created_at DESC 
LIMIT 20;

-- ç´¢å¼•ç›‘æ§æŸ¥è¯¢
SELECT 
    schema_name,
    table_name,
    index_name,
    cardinality,
    pages,
    size
FROM information_schema.statistics 
WHERE table_schema = 'wework_platform'
ORDER BY cardinality DESC;
```

### åˆ†åº“åˆ†è¡¨ç­–ç•¥
```java
@Configuration
public class ShardingConfiguration {
    
    // æ•°æ®æºé…ç½®
    @Bean
    public DataSource createShardingDataSource() {
        // åˆ†åº“ç­–ç•¥ï¼šæŒ‰ç§Ÿæˆ·IDåˆ†åº“
        DatabaseShardingStrategyConfiguration databaseShardingStrategy = 
            new DatabaseShardingStrategyConfiguration(
                "tenant_id", 
                new TenantDatabaseShardingAlgorithm()
            );
        
        // åˆ†è¡¨ç­–ç•¥ï¼šæŒ‰åˆ›å»ºæ—¶é—´åˆ†è¡¨ï¼ˆæœˆè¡¨ï¼‰
        TableShardingStrategyConfiguration tableShardingStrategy = 
            new TableShardingStrategyConfiguration(
                "created_at", 
                new DateBasedTableShardingAlgorithm()
            );
        
        // åˆ†ç‰‡è§„åˆ™é…ç½®
        ShardingRuleConfiguration shardingRule = new ShardingRuleConfiguration();
        
        // æ¶ˆæ¯è®°å½•è¡¨åˆ†ç‰‡é…ç½®
        TableRuleConfiguration messageTableRule = new TableRuleConfiguration("message_records");
        messageTableRule.setActualDataNodes("ds${0..3}.message_records_${202401..202412}");
        messageTableRule.setDatabaseShardingStrategyConfig(databaseShardingStrategy);
        messageTableRule.setTableShardingStrategyConfig(tableShardingStrategy);
        
        shardingRule.getTableRuleConfigs().add(messageTableRule);
        
        // åˆ›å»ºæ•°æ®æº
        return ShardingDataSourceFactory.createDataSource(createDataSourceMap(), shardingRule, new Properties());
    }
    
    private Map<String, DataSource> createDataSourceMap() {
        Map<String, DataSource> dataSourceMap = new HashMap<>();
        
        // åˆ›å»º4ä¸ªåˆ†åº“
        for (int i = 0; i < 4; i++) {
            HikariDataSource dataSource = new HikariDataSource();
            dataSource.setJdbcUrl("jdbc:mysql://db" + i + ":3306/wework_shard_" + i);
            dataSource.setUsername("root");
            dataSource.setPassword("password");
            dataSource.setMaximumPoolSize(20);
            dataSource.setMinimumIdle(5);
            
            dataSourceMap.put("ds" + i, dataSource);
        }
        
        return dataSourceMap;
    }
}

// åˆ†ç‰‡ç®—æ³•å®ç°
public class TenantDatabaseShardingAlgorithm implements PreciseShardingAlgorithm<String> {
    
    @Override
    public String doSharding(Collection<String> availableTargetNames, 
                           PreciseShardingValue<String> shardingValue) {
        String tenantId = shardingValue.getValue();
        
        // ä½¿ç”¨ç§Ÿæˆ·IDçš„å“ˆå¸Œå€¼åˆ†åº“
        int shardIndex = Math.abs(tenantId.hashCode()) % availableTargetNames.size();
        
        return "ds" + shardIndex;
    }
}

public class DateBasedTableShardingAlgorithm implements PreciseShardingAlgorithm<LocalDateTime> {
    
    @Override
    public String doSharding(Collection<String> availableTargetNames, 
                           PreciseShardingValue<LocalDateTime> shardingValue) {
        LocalDateTime createTime = shardingValue.getValue();
        
        // æŒ‰å¹´æœˆåˆ†è¡¨
        String suffix = createTime.format(DateTimeFormatter.ofPattern("yyyyMM"));
        String tableName = shardingValue.getLogicTableName() + "_" + suffix;
        
        return tableName;
    }
}
```

### è¯»å†™åˆ†ç¦»é…ç½®
```java
@Configuration
public class ReadWriteSplitConfiguration {
    
    @Bean
    @Primary
    public DataSource readWriteSplitDataSource() {
        // ä¸»åº“é…ç½®
        HikariDataSource masterDataSource = createDataSource("master", "jdbc:mysql://master-db:3306/wework");
        
        // ä»åº“é…ç½®
        HikariDataSource slave1DataSource = createDataSource("slave1", "jdbc:mysql://slave1-db:3306/wework");
        HikariDataSource slave2DataSource = createDataSource("slave2", "jdbc:mysql://slave2-db:3306/wework");
        
        Map<String, DataSource> dataSourceMap = new HashMap<>();
        dataSourceMap.put("master", masterDataSource);
        dataSourceMap.put("slave1", slave1DataSource);
        dataSourceMap.put("slave2", slave2DataSource);
        
        // è¯»å†™åˆ†ç¦»è§„åˆ™
        ReadWriteSplitRuleConfiguration readWriteSplitRule = new ReadWriteSplitRuleConfiguration(
            "readWriteSplit",
            "master",
            Arrays.asList("slave1", "slave2"),
            new RandomReplicaLoadBalanceAlgorithm()
        );
        
        return ReadWriteSplitDataSourceFactory.createDataSource(dataSourceMap, readWriteSplitRule, new Properties());
    }
    
    private HikariDataSource createDataSource(String name, String jdbcUrl) {
        HikariDataSource dataSource = new HikariDataSource();
        dataSource.setPoolName(name + "-pool");
        dataSource.setJdbcUrl(jdbcUrl);
        dataSource.setUsername("root");
        dataSource.setPassword("password");
        dataSource.setMaximumPoolSize(50);
        dataSource.setMinimumIdle(10);
        dataSource.setConnectionTimeout(30000);
        dataSource.setIdleTimeout(600000);
        dataSource.setMaxLifetime(1800000);
        dataSource.setLeakDetectionThreshold(60000);
        
        return dataSource;
    }
}

// å¼ºåˆ¶è¯»ä¸»åº“æ³¨è§£
@Target({ElementType.METHOD, ElementType.TYPE})
@Retention(RetentionPolicy.RUNTIME)
public @interface ForceMaster {
}

// è¯»å†™åˆ†ç¦»åˆ‡é¢
@Aspect
@Component
public class ReadWriteSplitAspect {
    
    @Around("@annotation(ForceMaster)")
    public Object forceMaster(ProceedingJoinPoint joinPoint) throws Throwable {
        try {
            // å¼ºåˆ¶ä½¿ç”¨ä¸»åº“
            HintManager.getInstance().setMasterRouteOnly();
            return joinPoint.proceed();
        } finally {
            HintManager.clear();
        }
    }
    
    @Around("@annotation(org.springframework.transaction.annotation.Transactional)")
    public Object transactional(ProceedingJoinPoint joinPoint) throws Throwable {
        try {
            // äº‹åŠ¡æ–¹æ³•å¼ºåˆ¶ä½¿ç”¨ä¸»åº“
            HintManager.getInstance().setMasterRouteOnly();
            return joinPoint.proceed();
        } finally {
            HintManager.clear();
        }
    }
}
```

## ğŸš€ ç¼“å­˜ä¼˜åŒ–ç­–ç•¥

### å¤šçº§ç¼“å­˜æ¶æ„
```java
@Configuration
@EnableCaching
public class MultiLevelCacheConfiguration {
    
    // L1ç¼“å­˜ï¼šæœ¬åœ°ç¼“å­˜ï¼ˆCaffeineï¼‰
    @Bean
    public CacheManager l1CacheManager() {
        CaffeineCacheManager cacheManager = new CaffeineCacheManager();
        cacheManager.setCaffeine(Caffeine.newBuilder()
            .maximumSize(10000)
            .expireAfterWrite(Duration.ofMinutes(5))
            .expireAfterAccess(Duration.ofMinutes(2))
            .recordStats()
            .build());
        return cacheManager;
    }
    
    // L2ç¼“å­˜ï¼šRedisåˆ†å¸ƒå¼ç¼“å­˜
    @Bean
    public CacheManager l2CacheManager(RedisConnectionFactory connectionFactory) {
        RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig()
            .entryTtl(Duration.ofMinutes(30))
            .serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer()))
            .serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new GenericJackson2JsonRedisSerializer()))
            .disableCachingNullValues();
        
        return RedisCacheManager.builder(connectionFactory)
            .cacheDefaults(config)
            .transactionAware()
            .build();
    }
    
    // å¤åˆç¼“å­˜ç®¡ç†å™¨
    @Bean
    @Primary
    public CacheManager compositeCacheManager() {
        CompositeCacheManager cacheManager = new CompositeCacheManager();
        cacheManager.setCacheManagers(Arrays.asList(l1CacheManager(), l2CacheManager(null)));
        cacheManager.setFallbackToNoOpCache(false);
        return cacheManager;
    }
}

@Component
public class MultiLevelCacheService {
    
    private final Cache<String, Object> l1Cache;
    private final RedisTemplate<String, Object> redisTemplate;
    
    public MultiLevelCacheService(CacheManager l1CacheManager, RedisTemplate<String, Object> redisTemplate) {
        this.l1Cache = l1CacheManager.getCache("default").getNativeCache();
        this.redisTemplate = redisTemplate;
    }
    
    public <T> T get(String key, Class<T> type) {
        // 1. å°è¯•ä»L1ç¼“å­˜è·å–
        T value = (T) l1Cache.getIfPresent(key);
        if (value != null) {
            return value;
        }
        
        // 2. å°è¯•ä»L2ç¼“å­˜è·å–
        value = (T) redisTemplate.opsForValue().get(key);
        if (value != null) {
            // å›å¡«L1ç¼“å­˜
            l1Cache.put(key, value);
            return value;
        }
        
        return null;
    }
    
    public void put(String key, Object value, Duration ttl) {
        // åŒæ—¶æ›´æ–°L1å’ŒL2ç¼“å­˜
        l1Cache.put(key, value);
        redisTemplate.opsForValue().set(key, value, ttl);
    }
    
    public void evict(String key) {
        // åŒæ—¶æ¸…é™¤L1å’ŒL2ç¼“å­˜
        l1Cache.invalidate(key);
        redisTemplate.delete(key);
    }
}
```

### ç¼“å­˜é˜²æŠ¤æœºåˆ¶
```java
@Component
public class CacheProtectionService {
    
    private final RedisTemplate<String, Object> redisTemplate;
    private final BloomFilter<String> bloomFilter;
    private final LoadingCache<String, Object> localCache;
    
    public CacheProtectionService(RedisTemplate<String, Object> redisTemplate) {
        this.redisTemplate = redisTemplate;
        
        // å¸ƒéš†è¿‡æ»¤å™¨é˜²æ­¢ç¼“å­˜ç©¿é€
        this.bloomFilter = BloomFilter.create(
            Funnels.stringFunnel(StandardCharsets.UTF_8),
            1000000,  // é¢„æœŸæ’å…¥æ•°é‡
            0.01      // è¯¯åˆ¤ç‡
        );
        
        // æœ¬åœ°ç¼“å­˜é˜²æ­¢ç¼“å­˜å‡»ç©¿
        this.localCache = Caffeine.newBuilder()
            .maximumSize(1000)
            .expireAfterWrite(Duration.ofMinutes(5))
            .build(this::loadFromDatabase);
    }
    
    // é˜²æ­¢ç¼“å­˜ç©¿é€
    public <T> T getWithBloomFilter(String key, Class<T> type, Supplier<T> dataLoader) {
        // 1. æ£€æŸ¥å¸ƒéš†è¿‡æ»¤å™¨
        if (!bloomFilter.mightContain(key)) {
            return null; // æ•°æ®è‚¯å®šä¸å­˜åœ¨
        }
        
        // 2. å°è¯•ä»ç¼“å­˜è·å–
        T value = (T) redisTemplate.opsForValue().get(key);
        if (value != null) {
            return value;
        }
        
        // 3. ä»æ•°æ®æºåŠ è½½
        value = dataLoader.get();
        if (value != null) {
            // åŠ å…¥ç¼“å­˜å’Œå¸ƒéš†è¿‡æ»¤å™¨
            redisTemplate.opsForValue().set(key, value, Duration.ofMinutes(30));
            bloomFilter.put(key);
        } else {
            // ç¼“å­˜ç©ºå€¼ï¼Œé˜²æ­¢ç¼“å­˜ç©¿é€
            redisTemplate.opsForValue().set(key, "NULL", Duration.ofMinutes(5));
        }
        
        return value;
    }
    
    // é˜²æ­¢ç¼“å­˜å‡»ç©¿ï¼ˆçƒ­ç‚¹æ•°æ®ï¼‰
    public <T> T getWithHotspotProtection(String key, Class<T> type, Supplier<T> dataLoader) {
        try {
            // ä½¿ç”¨æœ¬åœ°ç¼“å­˜çš„åŠ è½½æœºåˆ¶ï¼Œè‡ªå¸¦äº’æ–¥é”
            return (T) localCache.get(key);
        } catch (Exception e) {
            log.error("Failed to load data for key: " + key, e);
            return null;
        }
    }
    
    // é˜²æ­¢ç¼“å­˜é›ªå´©
    public void preloadCache(List<String> keys) {
        keys.parallelStream().forEach(key -> {
            try {
                // éšæœºå»¶è¿Ÿï¼Œé¿å…åŒæ—¶è¿‡æœŸ
                Thread.sleep(ThreadLocalRandom.current().nextInt(1000));
                
                Object value = loadFromDatabase(key);
                if (value != null) {
                    // éšæœºTTLï¼Œé¿å…åŒæ—¶è¿‡æœŸ
                    Duration ttl = Duration.ofMinutes(30 + ThreadLocalRandom.current().nextInt(10));
                    redisTemplate.opsForValue().set(key, value, ttl);
                }
            } catch (Exception e) {
                log.warn("Failed to preload cache for key: " + key, e);
            }
        });
    }
    
    private Object loadFromDatabase(String key) {
        // å®é™…çš„æ•°æ®åº“åŠ è½½é€»è¾‘
        return databaseService.findByKey(key);
    }
}

// ç¼“å­˜æ›´æ–°ç­–ç•¥
@Component
public class CacheUpdateService {
    
    private final RedisTemplate<String, Object> redisTemplate;
    private final MessageProducer messageProducer;
    
    // Cache-Asideæ¨¡å¼ï¼šå…ˆæ›´æ–°æ•°æ®åº“ï¼Œå†åˆ é™¤ç¼“å­˜
    @Transactional
    public void updateDataWithCacheAside(String id, Object newData) {
        try {
            // 1. æ›´æ–°æ•°æ®åº“
            databaseService.update(id, newData);
            
            // 2. åˆ é™¤ç¼“å­˜
            redisTemplate.delete("data:" + id);
            
            // 3. å‘é€ç¼“å­˜å¤±æ•ˆæ¶ˆæ¯
            messageProducer.sendCacheInvalidationMessage(id);
            
        } catch (Exception e) {
            log.error("Failed to update data with cache aside", e);
            throw new RuntimeException("Update failed", e);
        }
    }
    
    // Write-Throughæ¨¡å¼ï¼šåŒæ—¶æ›´æ–°æ•°æ®åº“å’Œç¼“å­˜
    @Transactional
    public void updateDataWithWriteThrough(String id, Object newData) {
        try {
            // 1. æ›´æ–°æ•°æ®åº“
            databaseService.update(id, newData);
            
            // 2. æ›´æ–°ç¼“å­˜
            redisTemplate.opsForValue().set("data:" + id, newData, Duration.ofMinutes(30));
            
        } catch (Exception e) {
            // å›æ»šæ“ä½œ
            log.error("Failed to update data with write through", e);
            throw new RuntimeException("Update failed", e);
        }
    }
    
    // Write-Behindæ¨¡å¼ï¼šå…ˆæ›´æ–°ç¼“å­˜ï¼Œå¼‚æ­¥æ›´æ–°æ•°æ®åº“
    public void updateDataWithWriteBehind(String id, Object newData) {
        try {
            // 1. ç«‹å³æ›´æ–°ç¼“å­˜
            redisTemplate.opsForValue().set("data:" + id, newData, Duration.ofMinutes(30));
            
            // 2. å¼‚æ­¥æ›´æ–°æ•°æ®åº“
            CompletableFuture.runAsync(() -> {
                try {
                    databaseService.update(id, newData);
                } catch (Exception e) {
                    log.error("Failed to update database asynchronously", e);
                    // å¯ä»¥è€ƒè™‘é‡è¯•æˆ–è€…å›æ»šç¼“å­˜
                }
            });
            
        } catch (Exception e) {
            log.error("Failed to update data with write behind", e);
            throw new RuntimeException("Update failed", e);
        }
    }
}
```

## ğŸŒ ç½‘ç»œä¸IOä¼˜åŒ–

### HTTPè¿æ¥ä¼˜åŒ–
```java
@Configuration
public class HttpClientOptimization {
    
    @Bean
    public RestTemplate optimizedRestTemplate() {
        // è¿æ¥æ± é…ç½®
        PoolingHttpClientConnectionManager connectionManager = new PoolingHttpClientConnectionManager();
        connectionManager.setMaxTotal(200);                    // æœ€å¤§è¿æ¥æ•°
        connectionManager.setDefaultMaxPerRoute(50);           // æ¯ä¸ªè·¯ç”±æœ€å¤§è¿æ¥æ•°
        connectionManager.setValidateAfterInactivity(2000);    // è¿æ¥æ£€æŸ¥é—´éš”
        
        // HTTPå®¢æˆ·ç«¯é…ç½®
        CloseableHttpClient httpClient = HttpClients.custom()
            .setConnectionManager(connectionManager)
            .setConnectionTimeToLive(30, TimeUnit.SECONDS)     // è¿æ¥å­˜æ´»æ—¶é—´
            .setDefaultRequestConfig(RequestConfig.custom()
                .setConnectTimeout(5000)                       // è¿æ¥è¶…æ—¶
                .setSocketTimeout(10000)                       // è¯»å–è¶…æ—¶
                .setConnectionRequestTimeout(3000)             // ä»è¿æ¥æ± è·å–è¿æ¥è¶…æ—¶
                .build())
            .setRetryHandler(new DefaultHttpRequestRetryHandler(3, true))  // é‡è¯•ç­–ç•¥
            .build();
        
        HttpComponentsClientHttpRequestFactory factory = new HttpComponentsClientHttpRequestFactory(httpClient);
        
        RestTemplate restTemplate = new RestTemplate(factory);
        
        // æ·»åŠ æ‹¦æˆªå™¨
        restTemplate.getInterceptors().add(new LoggingClientHttpRequestInterceptor());
        restTemplate.getInterceptors().add(new RetryInterceptor());
        
        return restTemplate;
    }
    
    @Bean
    public WebClient optimizedWebClient() {
        ConnectionProvider connectionProvider = ConnectionProvider.builder("optimized")
            .maxConnections(500)                    // æœ€å¤§è¿æ¥æ•°
            .maxIdleTime(Duration.ofSeconds(20))    // è¿æ¥ç©ºé—²æ—¶é—´
            .maxLifeTime(Duration.ofSeconds(60))    // è¿æ¥æœ€å¤§å­˜æ´»æ—¶é—´
            .pendingAcquireTimeout(Duration.ofSeconds(60))  // è·å–è¿æ¥è¶…æ—¶
            .evictInBackground(Duration.ofSeconds(120))     // åå°æ¸…ç†é—´éš”
            .build();
        
        HttpClient httpClient = HttpClient.create(connectionProvider)
            .option(ChannelOption.CONNECT_TIMEOUT_MILLIS, 5000)     // è¿æ¥è¶…æ—¶
            .option(ChannelOption.SO_KEEPALIVE, true)               // å¯ç”¨TCP Keep-Alive
            .option(ChannelOption.TCP_NODELAY, true)                // ç¦ç”¨Nagleç®—æ³•
            .responseTimeout(Duration.ofSeconds(10))                // å“åº”è¶…æ—¶
            .compress(true);                                        // å¯ç”¨å‹ç¼©
        
        return WebClient.builder()
            .clientConnector(new ReactorClientHttpConnector(httpClient))
            .codecs(configurer -> configurer.defaultCodecs().maxInMemorySize(10 * 1024 * 1024)) // 10MB
            .build();
    }
}

// æ‰¹é‡HTTPè¯·æ±‚ä¼˜åŒ–
@Component
public class BatchHttpService {
    
    private final WebClient webClient;
    
    public BatchHttpService(WebClient optimizedWebClient) {
        this.webClient = optimizedWebClient;
    }
    
    public List<ResponseEntity<String>> batchRequest(List<String> urls) {
        List<Mono<ResponseEntity<String>>> requests = urls.stream()
            .map(url -> webClient.get()
                .uri(url)
                .retrieve()
                .toEntity(String.class)
                .timeout(Duration.ofSeconds(10))
                .onErrorReturn(ResponseEntity.status(HttpStatus.REQUEST_TIMEOUT).build()))
            .collect(Collectors.toList());
        
        // å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰è¯·æ±‚
        return Flux.merge(requests)
            .collectList()
            .block(Duration.ofSeconds(30));
    }
    
    // é™æµæ‰¹é‡è¯·æ±‚
    public Flux<ResponseEntity<String>> batchRequestWithRateLimit(List<String> urls, int maxConcurrency) {
        return Flux.fromIterable(urls)
            .flatMap(url -> webClient.get()
                .uri(url)
                .retrieve()
                .toEntity(String.class)
                .timeout(Duration.ofSeconds(10))
                .onErrorReturn(ResponseEntity.status(HttpStatus.REQUEST_TIMEOUT).build()),
                maxConcurrency); // é™åˆ¶å¹¶å‘æ•°
    }
}
```

### æ–‡ä»¶IOä¼˜åŒ–
```java
@Component
public class FileIOOptimization {
    
    // NIOæ–‡ä»¶æ“ä½œä¼˜åŒ–
    public void writeFileWithNIO(Path filePath, List<String> lines) throws IOException {
        try (BufferedWriter writer = Files.newBufferedWriter(filePath, 
                StandardCharsets.UTF_8, 
                StandardOpenOption.CREATE, 
                StandardOpenOption.WRITE,
                StandardOpenOption.TRUNCATE_EXISTING)) {
            
            for (String line : lines) {
                writer.write(line);
                writer.newLine();
            }
            
            writer.flush();
        }
    }
    
    public List<String> readFileWithNIO(Path filePath) throws IOException {
        return Files.readAllLines(filePath, StandardCharsets.UTF_8);
    }
    
    // å¤§æ–‡ä»¶æµå¼å¤„ç†
    public void processLargeFile(Path filePath, Consumer<String> lineProcessor) throws IOException {
        try (Stream<String> lines = Files.lines(filePath, StandardCharsets.UTF_8)) {
            lines.parallel()
                .filter(line -> !line.trim().isEmpty())
                .forEach(lineProcessor);
        }
    }
    
    // å†…å­˜æ˜ å°„æ–‡ä»¶æ“ä½œ
    public void processFileWithMemoryMapping(Path filePath) throws IOException {
        try (RandomAccessFile file = new RandomAccessFile(filePath.toFile(), "r");
             FileChannel channel = file.getChannel()) {
            
            long fileSize = channel.size();
            MappedByteBuffer buffer = channel.map(FileChannel.MapMode.READ_ONLY, 0, fileSize);
            
            // å¤„ç†æ˜ å°„çš„ç¼“å†²åŒº
            processBuffer(buffer);
        }
    }
    
    // é›¶æ‹·è´æ–‡ä»¶ä¼ è¾“
    public void transferFile(Path source, Path target) throws IOException {
        try (FileChannel sourceChannel = FileChannel.open(source, StandardOpenOption.READ);
             FileChannel targetChannel = FileChannel.open(target, 
                 StandardOpenOption.CREATE, 
                 StandardOpenOption.WRITE,
                 StandardOpenOption.TRUNCATE_EXISTING)) {
            
            long position = 0;
            long size = sourceChannel.size();
            
            while (position < size) {
                long transferred = sourceChannel.transferTo(position, size - position, targetChannel);
                position += transferred;
            }
        }
    }
    
    // å¼‚æ­¥æ–‡ä»¶æ“ä½œ
    @Async("ioExecutor")
    public CompletableFuture<String> readFileAsync(Path filePath) {
        return CompletableFuture.supplyAsync(() -> {
            try {
                return Files.readString(filePath, StandardCharsets.UTF_8);
            } catch (IOException e) {
                throw new RuntimeException("Failed to read file", e);
            }
        });
    }
    
    @Async("ioExecutor")
    public CompletableFuture<Void> writeFileAsync(Path filePath, String content) {
        return CompletableFuture.runAsync(() -> {
            try {
                Files.writeString(filePath, content, StandardCharsets.UTF_8,
                    StandardOpenOption.CREATE,
                    StandardOpenOption.WRITE,
                    StandardOpenOption.TRUNCATE_EXISTING);
            } catch (IOException e) {
                throw new RuntimeException("Failed to write file", e);
            }
        });
    }
}
```

## ğŸ“Š æ¶ˆæ¯é˜Ÿåˆ—æ€§èƒ½ä¼˜åŒ–

### Redisæ¶ˆæ¯é˜Ÿåˆ—ä¼˜åŒ–
```java
@Configuration
public class RedisMessageQueueOptimization {
    
    @Bean
    public RedisTemplate<String, Object> optimizedRedisTemplate(RedisConnectionFactory connectionFactory) {
        RedisTemplate<String, Object> template = new RedisTemplate<>();
        template.setConnectionFactory(connectionFactory);
        
        // ä½¿ç”¨æ›´é«˜æ•ˆçš„åºåˆ—åŒ–å™¨
        template.setKeySerializer(new StringRedisSerializer());
        template.setHashKeySerializer(new StringRedisSerializer());
        template.setValueSerializer(new GenericFastJsonRedisSerializer());
        template.setHashValueSerializer(new GenericFastJsonRedisSerializer());
        
        template.setDefaultSerializer(new GenericFastJsonRedisSerializer());
        template.afterPropertiesSet();
        
        return template;
    }
    
    @Bean
    public RedissonClient redissonClient() {
        Config config = new Config();
        config.useSingleServer()
            .setAddress("redis://localhost:6379")
            .setConnectionMinimumIdleSize(10)
            .setConnectionPoolSize(50)
            .setDnsMonitoringInterval(5000)
            .setSubscriptionConnectionMinimumIdleSize(1)
            .setSubscriptionConnectionPoolSize(25)
            .setSubscriptionsPerConnection(5)
            .setIdleConnectionTimeout(10000)
            .setConnectTimeout(10000)
            .setTimeout(3000)
            .setRetryAttempts(3)
            .setRetryInterval(1500);
        
        return Redisson.create(config);
    }
}

@Component
public class OptimizedRedisMessageQueue {
    
    private final RedisTemplate<String, Object> redisTemplate;
    private final RedissonClient redissonClient;
    
    // æ‰¹é‡æ¶ˆæ¯å‘é€
    public void sendMessagesBatch(String queueName, List<Object> messages) {
        redisTemplate.executePipelined((RedisCallback<Object>) connection -> {
            for (Object message : messages) {
                byte[] key = queueName.getBytes(StandardCharsets.UTF_8);
                byte[] value = serialize(message);
                connection.lPush(key, value);
            }
            return null;
        });
    }
    
    // ä¼˜åŒ–çš„æ¶ˆæ¯æ¶ˆè´¹
    public List<Object> consumeMessagesBatch(String queueName, int batchSize, Duration timeout) {
        List<Object> messages = new ArrayList<>();
        
        // ä½¿ç”¨é˜»å¡å¼¹å‡ºè·å–æ¶ˆæ¯
        List<Object> result = redisTemplate.opsForList().rightPop(queueName, batchSize, timeout);
        
        if (result != null) {
            messages.addAll(result);
        }
        
        return messages;
    }
    
    // å»¶æ—¶æ¶ˆæ¯é˜Ÿåˆ—ï¼ˆåŸºäºZSetï¼‰
    public void sendDelayedMessage(String queueName, Object message, Duration delay) {
        long score = System.currentTimeMillis() + delay.toMillis();
        redisTemplate.opsForZSet().add(queueName + ":delayed", serialize(message), score);
    }
    
    // å»¶æ—¶æ¶ˆæ¯æ¶ˆè´¹
    @Scheduled(fixedDelay = 1000)
    public void processDelayedMessages() {
        String delayedQueueName = "message_queue:delayed";
        long now = System.currentTimeMillis();
        
        // è·å–åˆ°æœŸçš„æ¶ˆæ¯
        Set<ZSetOperations.TypedTuple<Object>> expiredMessages = 
            redisTemplate.opsForZSet().rangeByScoreWithScores(delayedQueueName, 0, now);
        
        if (!expiredMessages.isEmpty()) {
            // æ‰¹é‡ç§»é™¤å·²å¤„ç†çš„æ¶ˆæ¯
            Object[] values = expiredMessages.stream()
                .map(ZSetOperations.TypedTuple::getValue)
                .toArray();
            
            redisTemplate.opsForZSet().remove(delayedQueueName, values);
            
            // å¤„ç†æ¶ˆæ¯
            expiredMessages.forEach(message -> {
                processMessage(message.getValue());
            });
        }
    }
    
    // ä¼˜å…ˆçº§é˜Ÿåˆ—å®ç°
    public void sendPriorityMessage(String queueName, Object message, int priority) {
        String priorityQueue = queueName + ":priority:" + priority;
        redisTemplate.opsForList().leftPush(priorityQueue, message);
    }
    
    public Object consumePriorityMessage(String queueName) {
        // æŒ‰ä¼˜å…ˆçº§ä»é«˜åˆ°ä½æ¶ˆè´¹
        for (int priority = 10; priority >= 1; priority--) {
            String priorityQueue = queueName + ":priority:" + priority;
            Object message = redisTemplate.opsForList().rightPop(priorityQueue, Duration.ofSeconds(1));
            if (message != null) {
                return message;
            }
        }
        return null;
    }
    
    // æ¶ˆæ¯å‹ç¼©
    public void sendCompressedMessage(String queueName, Object message) {
        try {
            byte[] data = serialize(message);
            byte[] compressed = compress(data);
            
            redisTemplate.opsForList().leftPush(queueName + ":compressed", compressed);
        } catch (Exception e) {
            log.error("Failed to send compressed message", e);
        }
    }
    
    private byte[] compress(byte[] data) throws IOException {
        ByteArrayOutputStream baos = new ByteArrayOutputStream();
        try (GZIPOutputStream gzipOut = new GZIPOutputStream(baos)) {
            gzipOut.write(data);
        }
        return baos.toByteArray();
    }
    
    private byte[] decompress(byte[] compressed) throws IOException {
        ByteArrayInputStream bais = new ByteArrayInputStream(compressed);
        ByteArrayOutputStream baos = new ByteArrayOutputStream();
        
        try (GZIPInputStream gzipIn = new GZIPInputStream(bais)) {
            byte[] buffer = new byte[1024];
            int len;
            while ((len = gzipIn.read(buffer)) != -1) {
                baos.write(buffer, 0, len);
            }
        }
        
        return baos.toByteArray();
    }
}
```

## ğŸ”§ ç³»ç»Ÿçº§æ€§èƒ½ä¼˜åŒ–

### å®¹å™¨èµ„æºä¼˜åŒ–
```dockerfile
# å¤šé˜¶æ®µæ„å»ºä¼˜åŒ–é•œåƒå¤§å°
FROM openjdk:17-jdk-slim as builder
WORKDIR /app
COPY . .
RUN ./mvnw clean package -DskipTests

FROM openjdk:17-jre-slim
WORKDIR /app

# åˆ›å»ºérootç”¨æˆ·
RUN groupadd -r appuser && useradd -r -g appuser appuser

# ä¼˜åŒ–JVMå‚æ•°
ENV JAVA_OPTS="-server \
    -XX:+UseG1GC \
    -XX:MaxGCPauseMillis=100 \
    -XX:+UseStringDeduplication \
    -XX:+OptimizeStringConcat \
    -Djava.security.egd=file:/dev/./urandom \
    -Dspring.backgroundpreinitializer.ignore=true"

# å¤åˆ¶åº”ç”¨
COPY --from=builder /app/target/*.jar app.jar

# åˆ‡æ¢åˆ°érootç”¨æˆ·
USER appuser

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8080/actuator/health || exit 1

EXPOSE 8080

ENTRYPOINT ["sh", "-c", "java $JAVA_OPTS -jar app.jar"]
```

```yaml
# Kuberneteséƒ¨ç½²ä¼˜åŒ–
apiVersion: apps/v1
kind: Deployment
metadata:
  name: wework-api
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  selector:
    matchLabels:
      app: wework-api
  template:
    metadata:
      labels:
        app: wework-api
    spec:
      # äº²å’Œæ€§é…ç½®
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                - key: app
                  operator: In
                  values:
                  - wework-api
              topologyKey: kubernetes.io/hostname
      
      containers:
      - name: wework-api
        image: wework-api:latest
        resources:
          requests:
            memory: "2Gi"
            cpu: "1000m"
          limits:
            memory: "4Gi"
            cpu: "2000m"
        
        # ç¯å¢ƒå˜é‡ä¼˜åŒ–
        env:
        - name: SPRING_PROFILES_ACTIVE
          value: "prod"
        - name: JAVA_OPTS
          value: "-Xms2g -Xmx3g -XX:+UseG1GC"
        
        # æ¢é’ˆé…ç½®
        livenessProbe:
          httpGet:
            path: /actuator/health/liveness
            port: 8080
          initialDelaySeconds: 60
          periodSeconds: 30
          timeoutSeconds: 5
          failureThreshold: 3
        
        readinessProbe:
          httpGet:
            path: /actuator/health/readiness
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 3
          failureThreshold: 3
        
        # å¯åŠ¨æ¢é’ˆ
        startupProbe:
          httpGet:
            path: /actuator/health
            port: 8080
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 3
          failureThreshold: 10
        
        ports:
        - containerPort: 8080
          name: http
        
        # æŒ‚è½½å·
        volumeMounts:
        - name: logs
          mountPath: /app/logs
        - name: config
          mountPath: /app/config
          readOnly: true
      
      volumes:
      - name: logs
        emptyDir: {}
      - name: config
        configMap:
          name: wework-api-config

---
# HPAè‡ªåŠ¨æ‰©ç¼©å®¹
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: wework-api-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: wework-api
  minReplicas: 3
  maxReplicas: 20
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
```

### ç›‘æ§å’Œè°ƒä¼˜å·¥å…·é›†æˆ
```java
@Configuration
@EnableScheduling
public class PerformanceMonitoringConfiguration {
    
    @Bean
    public MeterRegistry meterRegistry() {
        return new PrometheusMeterRegistry(PrometheusConfig.DEFAULT);
    }
    
    @Bean
    public TimedAspect timedAspect(MeterRegistry registry) {
        return new TimedAspect(registry);
    }
    
    @Bean
    public CountedAspect countedAspect(MeterRegistry registry) {
        return new CountedAspect(registry);
    }
}

@Component
public class PerformanceMonitor {
    
    private final MeterRegistry meterRegistry;
    private final MemoryMXBean memoryMXBean;
    private final GarbageCollectorMXBean[] gcMXBeans;
    
    public PerformanceMonitor(MeterRegistry meterRegistry) {
        this.meterRegistry = meterRegistry;
        this.memoryMXBean = ManagementFactory.getMemoryMXBean();
        this.gcMXBeans = ManagementFactory.getGarbageCollectorMXBeans().toArray(new GarbageCollectorMXBean[0]);
        
        setupMetrics();
    }
    
    private void setupMetrics() {
        // JVMå†…å­˜ç›‘æ§
        Gauge.builder("jvm.memory.heap.used")
            .register(meterRegistry, memoryMXBean, bean -> bean.getHeapMemoryUsage().getUsed());
        
        Gauge.builder("jvm.memory.heap.max")
            .register(meterRegistry, memoryMXBean, bean -> bean.getHeapMemoryUsage().getMax());
        
        Gauge.builder("jvm.memory.nonheap.used")
            .register(meterRegistry, memoryMXBean, bean -> bean.getNonHeapMemoryUsage().getUsed());
        
        // GCç›‘æ§
        for (GarbageCollectorMXBean gcBean : gcMXBeans) {
            Gauge.builder("jvm.gc.collection.count")
                .tag("gc", gcBean.getName())
                .register(meterRegistry, gcBean, GarbageCollectorMXBean::getCollectionCount);
            
            Gauge.builder("jvm.gc.collection.time")
                .tag("gc", gcBean.getName())
                .register(meterRegistry, gcBean, GarbageCollectorMXBean::getCollectionTime);
        }
        
        // çº¿ç¨‹ç›‘æ§
        ThreadMXBean threadBean = ManagementFactory.getThreadMXBean();
        Gauge.builder("jvm.threads.count")
            .register(meterRegistry, threadBean, ThreadMXBean::getThreadCount);
        
        Gauge.builder("jvm.threads.daemon.count")
            .register(meterRegistry, threadBean, ThreadMXBean::getDaemonThreadCount);
    }
    
    // å®šæœŸæ€§èƒ½æ£€æŸ¥
    @Scheduled(fixedRate = 60000) // æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
    public void performanceCheck() {
        MemoryUsage heapUsage = memoryMXBean.getHeapMemoryUsage();
        double heapUsedPercentage = (double) heapUsage.getUsed() / heapUsage.getMax() * 100;
        
        if (heapUsedPercentage > 85) {
            log.warn("High heap memory usage: {}%", String.format("%.2f", heapUsedPercentage));
            
            // è§¦å‘å‘Šè­¦
            alertService.sendPerformanceAlert("HIGH_MEMORY_USAGE", heapUsedPercentage);
        }
        
        // æ£€æŸ¥GCé¢‘ç‡
        for (GarbageCollectorMXBean gcBean : gcMXBeans) {
            long gcCount = gcBean.getCollectionCount();
            long gcTime = gcBean.getCollectionTime();
            
            // è®°å½•GCæŒ‡æ ‡
            meterRegistry.counter("gc.collections", "gc", gcBean.getName()).increment(gcCount);
            meterRegistry.timer("gc.time", "gc", gcBean.getName()).record(gcTime, TimeUnit.MILLISECONDS);
        }
    }
    
    // æ€§èƒ½æŒ‡æ ‡æ”¶é›†
    @EventListener
    public void handleApiRequest(ApiRequestEvent event) {
        Timer.Sample sample = Timer.start(meterRegistry);
        
        // è¯·æ±‚å®Œæˆåè®°å½•
        sample.stop(Timer.builder("api.request.duration")
            .tag("endpoint", event.getEndpoint())
            .tag("method", event.getMethod())
            .tag("status", String.valueOf(event.getStatus()))
            .register(meterRegistry));
        
        // è®°å½•è¯·æ±‚é‡
        meterRegistry.counter("api.requests.total",
            "endpoint", event.getEndpoint(),
            "method", event.getMethod(),
            "status", String.valueOf(event.getStatus()))
            .increment();
    }
}

// æ€§èƒ½åˆ†æåˆ‡é¢
@Aspect
@Component
public class PerformanceAnalysisAspect {
    
    private final MeterRegistry meterRegistry;
    
    @Around("@annotation(Timed)")
    public Object measureExecutionTime(ProceedingJoinPoint joinPoint) throws Throwable {
        Timer.Sample sample = Timer.start(meterRegistry);
        
        try {
            return joinPoint.proceed();
        } finally {
            String methodName = joinPoint.getSignature().getName();
            String className = joinPoint.getTarget().getClass().getSimpleName();
            
            sample.stop(Timer.builder("method.execution.time")
                .tag("class", className)
                .tag("method", methodName)
                .register(meterRegistry));
        }
    }
    
    @Around("execution(* com.wework.service.*.*(..))")
    public Object monitorServiceMethods(ProceedingJoinPoint joinPoint) throws Throwable {
        long startTime = System.nanoTime();
        String methodName = joinPoint.getSignature().getName();
        
        try {
            Object result = joinPoint.proceed();
            
            // è®°å½•æˆåŠŸæ‰§è¡Œ
            long duration = System.nanoTime() - startTime;
            meterRegistry.timer("service.method.duration",
                "method", methodName,
                "status", "success")
                .record(duration, TimeUnit.NANOSECONDS);
            
            return result;
        } catch (Exception e) {
            // è®°å½•å¼‚å¸¸
            long duration = System.nanoTime() - startTime;
            meterRegistry.timer("service.method.duration",
                "method", methodName,
                "status", "error")
                .record(duration, TimeUnit.NANOSECONDS);
            
            meterRegistry.counter("service.method.errors",
                "method", methodName,
                "exception", e.getClass().getSimpleName())
                .increment();
            
            throw e;
        }
    }
}
```

## ğŸ¯ æ€§èƒ½ä¼˜åŒ–æ€»ç»“

### æ ¸å¿ƒä¼˜åŒ–ç­–ç•¥
1. **åº”ç”¨å±‚ä¼˜åŒ–**: JVMè°ƒä¼˜ã€å¼‚æ­¥å¤„ç†ã€è¿æ¥æ± ä¼˜åŒ–
2. **æ•°æ®åº“ä¼˜åŒ–**: æŸ¥è¯¢ä¼˜åŒ–ã€ç´¢å¼•è®¾è®¡ã€åˆ†åº“åˆ†è¡¨ã€è¯»å†™åˆ†ç¦»
3. **ç¼“å­˜ä¼˜åŒ–**: å¤šçº§ç¼“å­˜ã€ç¼“å­˜é˜²æŠ¤ã€æ™ºèƒ½æ·˜æ±°ç­–ç•¥
4. **ç½‘ç»œä¼˜åŒ–**: è¿æ¥å¤ç”¨ã€æ‰¹é‡å¤„ç†ã€æ•°æ®å‹ç¼©
5. **ç³»ç»Ÿä¼˜åŒ–**: èµ„æºç®¡ç†ã€å®¹å™¨åŒ–ã€è‡ªåŠ¨æ‰©ç¼©å®¹

### æ€§èƒ½æŒ‡æ ‡
- **å“åº”æ—¶é—´**: P99 < 200ms, P95 < 100ms
- **ååé‡**: > 10,000 QPS
- **èµ„æºåˆ©ç”¨ç‡**: CPU < 70%, Memory < 80%
- **å¯ç”¨æ€§**: > 99.9%
- **æ‰©å±•æ€§**: æ”¯æŒ100+èŠ‚ç‚¹æ°´å¹³æ‰©å±•

### ç›‘æ§ä½“ç³»
- **JVMç›‘æ§**: å†…å­˜ã€GCã€çº¿ç¨‹ç›‘æ§
- **åº”ç”¨ç›‘æ§**: APIå“åº”æ—¶é—´ã€é”™è¯¯ç‡ã€ä¸šåŠ¡æŒ‡æ ‡
- **ç³»ç»Ÿç›‘æ§**: CPUã€å†…å­˜ã€ç½‘ç»œã€ç£ç›˜IO
- **å‘Šè­¦æœºåˆ¶**: æ™ºèƒ½é˜ˆå€¼ã€å¤šæ¸ é“é€šçŸ¥
- **æ€§èƒ½åˆ†æ**: çƒ­ç‚¹åˆ†æã€ç“¶é¢ˆè¯†åˆ«ã€ä¼˜åŒ–å»ºè®®
